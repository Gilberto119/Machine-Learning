# -*- coding: utf-8 -*-
"""RegresionLogistica.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uk6xnMsUYfYDHkP1dFdzBgyzxdKmjxjP
"""

import pandas as pd
import numpy as np

import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
import plotly.express as px
import plotly.figure_factory as ff
import plotly.graph_objects as go
from wordcloud import WordCloud

import nltk

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
sns.set_theme(style="dark")
mpl.rcParams['axes.unicode_minus'] = False
pd.set_option('display.max_columns',None)
plt.style.use('seaborn-dark-palette')

"""#Data Exploration """

df = pd.read_csv('/content/Iris.csv')
df['No_Species'] = 0
df.loc[df['Species'] == 'Iris-setosa', 'No_Species'] = 0
df.loc[df['Species'] == 'Iris-versicolor', 'No_Species'] = 1
df.loc[df['Species'] == 'Iris-virginica', 'No_Species'] = 2
df.head()

df.describe()

df["Species"].value_counts()

##Checar valores no nulos
df.notnull().sum()

##Checar valores nulos
df.isnull().sum()

##Checar blancos
df.isna().sum()

plt.figure(figsize = (10,8))
sns.heatmap(pd.DataFrame(df).corr(), annot=True)
plt.title('Correlation of Variables')
plt.show()

x = df[['Id','SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].values
classes = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}
y = df['No_Species'].values  # variable dependiente
df.info()

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier

from sklearn import metrics
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score

name ='Regresion Logistica'
logistic = LogisticRegression()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42)



names = []
accu_scores = []
accuracies = []

logistic.fit(X_train, y_train)
y_pred = logistic.predict(X_test)

accu_scores.append(accuracy_score(y_test, y_pred))
names.append(name)
tr_split = pd.DataFrame({'Name': names, 'Score': accu_scores})
print(tr_split)

logistic.fit(X_train, y_train)
y_pred = logistic.predict(X_test)
print("Matriz de Confusión para ", name, confusion_matrix(y_test,y_pred))
print("Reporte de Clasificación para ", name, classification_report(y_test,y_pred))

logistic = LogisticRegression()
logistic.fit(X_train, y_train)

y_pred_RF = logistic.predict(X_test)

df_pred = pd.DataFrame(y_pred_RF)
df_pred.columns = ['Predicted Value']
df_real = pd.DataFrame(y_test)
df_real.columns = ['Real Values']

df_sub = pd.read_csv('Iris.csv')
df_sub = df_sub.drop('Species', axis = 1)

# Reset index to prevent NaN values in concat result
df_pred.reset_index(drop=True, inplace=True)
df_sub.reset_index(drop=True, inplace=True)

# True values y predicted values
result = pd.concat([df_sub,df_pred,df_real], axis=1)
result.head(50)

from sklearn.model_selection import KFold
from sklearn.metrics import make_scorer
from sklearn.model_selection import cross_validate

kfold = KFold(n_splits=30, shuffle=True, random_state=42)
scorer = make_scorer(accuracy_score)

veracity = cross_validate(logistic, x, y, cv=kfold, scoring=scorer)

acur = veracity['test_score']
var = veracity['test_score'].var()
m = veracity['test_score'].mean()
sd = veracity['test_score'].std()


print("Accuracy of the Linear Regretion", "model with k-fold cross validation")
print("K-fold accuracies: ", acur)
print("Mean :", m)
print("Variance: ",var )
print("Standard deviation: ", sd)
print("Bias: ", 1 - m)

from sklearn.model_selection import learning_curve
from sklearn.model_selection import ShuffleSplit

train_sizes, train_scores, test_scores = learning_curve(logistic, X_test, y_test, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, train_sizes=np.linspace(0.01, 1.0, 50), verbose=0)

train_scores_mean = -train_scores.mean(axis = 1)
train_scores_std = train_scores.std(axis = 1)
test_scores_mean = -test_scores.mean(axis = 1)
test_scores_std = test_scores.std(axis = 1)


plt.figure(figsize=(25, 8))
plt.style.use('seaborn-whitegrid')
plt.title('Curva de Aprendizaje')
plt.xlabel('Tamaño del Conjunto de Entrenamiento')
plt.ylabel('Error Cuadrático Medio')
plt.grid()

plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r")
plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="#2DD6A0")

plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Entrenamiento")
plt.plot(train_sizes, test_scores_mean, 'o-', color="#2DD6A0", label="Validación Cruzada")

plt.ylim(-0.1, 1.1)
plt.legend(loc="best")
plt.show()